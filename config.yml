model_params:
  model: MultiHeadNet
  arch: "resnet34"
  pretrained: True
  num_classes: [168, 11, 7]

args:
  logdir: "./logs/bengali_logs"
  seed: 65
  check: False
  verbose: True

runner_params:  # OPTIONAL KEYWORD, параметры для инициализации Runner
  # Например для SupervisedRunner
  input_key: "image"  # Пример
  output_key:
    - "logit_grapheme_root"
    - "logit_vowel_diacritic"
    - "logit_consonant_diacritic"
  input_target_key:
    - "grapheme_root"
    - "vowel_diacritic"
    - "consonant_diacritic"

stages:
  data_params:
    batch_size: 128
    num_workers: 2

    train_csv: "train.csv"
    data_folder: "../input/grapheme-imgs-128x128/"

  state_params:
    main_metric: hmar
    minimize_metric: False

  criterion_params:
    _key_value: True
    ce:
      criterion: CrossEntropyLoss

  callbacks_params:
    loss_grapheme_roots:
      callback: CriterionCallback
      input_key: "grapheme_root"
      output_key: "logit_grapheme_root"
      criterion_key: "ce"
      prefix: "loss_gr"

    loss_vowel_diacritics:
      callback: CriterionCallback
      input_key: "vowel_diacritic"
      output_key: "logit_vowel_diacritic"
      criterion_key: "ce"
      prefix: "loss_vd"

    loss_consonant_diacritics:
      callback: CriterionCallback
      input_key: "consonant_diacritic"
      output_key: "logit_consonant_diacritic"
      criterion_key: "ce"
      prefix: "loss_cd"

    loss_aggregator:
      callback: CriterionAggregatorCallback
      prefix: "loss"
      loss_aggregate_fn: "sum"
      loss_keys: ["loss_gr", "loss_vd", "loss_cd"]

    saver:
      callback: CheckpointCallback
      save_n_best: 2

    metrics:
      callback: HMacroAveragedRecall

    optimizer:
      callback: OptimizerCallback

    scheduler:
      callback: SchedulerCallback
      reduce_metric: loss

  stage1:  # Все, что не ключевое слово, расценивается, как имя стейджа. Для тренировки в Catalyst требуется хотябы один стейдж. Имя может быть произвольным
    state_params:  # Вы можете переопределить любые параметры, для конкретного стейджа, например
      num_epochs: 3

    callbacks_params:
      freeze:
        callback: FreezeCallback

    optimizer_params:  # Пример, переопределенного оптимизатора
      optimizer: AdamW
      lr: 0.001

    scheduler_params:
      scheduler: MultiStepLR
      milestones:
      - 3
      gamma: 0.1

  stage2:
    state_params:
      num_epochs: 20

    callbacks_params:
      unfreeze:
        callback: UnFreezeCallback

    optimizer_params:  # Пример, переопределенного оптимизатора
      optimizer: AdamW
      lr: 0.0002

    scheduler_params:
      scheduler: OneCycleLRWithWarmup
      num_steps: 20
      lr_range: [0.0005, 0.00001]
      momentum_range: [0.85, 0.95]


